#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†å›¾è°±æ„å»ºDemoä¸»ç¨‹åº

æ¼”ç¤ºçŸ¥è¯†å›¾è°±æ„å»ºçš„å››ä¸ªä¸»è¦æ­¥éª¤ï¼š
1. ä¸»ä½“å®šä¹‰ (Entity Definition)
2. çŸ¥è¯†æŠ½å– (Knowledge Extraction) 
3. çŸ¥è¯†æ˜ å°„ (Knowledge Mapping)
4. çŸ¥è¯†èåˆ (Knowledge Fusion)
"""

import os
import sys
import argparse
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from kg_demo.entity_definition.ontology import Ontology
from kg_demo.entity_definition.entity_types import Entity, EntityTypes
from kg_demo.entity_definition.relation_types import Relation, RelationTypes

from kg_demo.knowledge_extraction.text_extractor import TextExtractor
from kg_demo.knowledge_extraction.entity_extractor import EntityExtractor
from kg_demo.knowledge_extraction.relation_extractor import RelationExtractor
from kg_demo.knowledge_extraction.pattern_extractor import PatternExtractor

from kg_demo.knowledge_mapping.entity_mapper import EntityMapper
from kg_demo.knowledge_mapping.relation_mapper import RelationMapper
from kg_demo.knowledge_mapping.ontology_mapper import OntologyMapper
from kg_demo.knowledge_mapping.similarity_calculator import SimilarityCalculator

from kg_demo.knowledge_fusion.entity_fusion import EntityFusion
from kg_demo.knowledge_fusion.relation_fusion import RelationFusion
from kg_demo.knowledge_fusion.conflict_resolution import ConflictResolver
from kg_demo.knowledge_fusion.knowledge_graph import KnowledgeGraph

from kg_demo.data.sample_data import SampleDataGenerator


class KnowledgeGraphDemo:
    """çŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤º"""
    
    def __init__(self):
        print("ğŸš€ åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤ºç³»ç»Ÿ...")
        self.ontology = Ontology()
        self.knowledge_graph = KnowledgeGraph(self.ontology)
        self.sample_data = SampleDataGenerator()
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.text_extractor = TextExtractor()
        self.entity_extractor = EntityExtractor()
        self.relation_extractor = RelationExtractor()
        self.pattern_extractor = PatternExtractor()
        
        self.entity_mapper = EntityMapper()
        self.relation_mapper = RelationMapper(self.ontology)
        self.ontology_mapper = OntologyMapper(self.ontology)
        
        self.entity_fusion = EntityFusion()
        self.relation_fusion = RelationFusion()
        self.conflict_resolver = ConflictResolver()
        
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!\n")
    
    def step1_ontology_definition(self):
        """æ­¥éª¤1: ä¸»ä½“å®šä¹‰"""
        print("=" * 60)
        print("ğŸ“‹ æ­¥éª¤1: ä¸»ä½“å®šä¹‰ (Ontology Definition)")
        print("=" * 60)
        
        print("ğŸ”§ æ„å»ºçŸ¥è¯†å›¾è°±æœ¬ä½“ç»“æ„...")
        
        # æ˜¾ç¤ºé»˜è®¤æœ¬ä½“
        self.ontology.print_ontology_summary()
        
        # å¯¼å‡ºæœ¬ä½“
        ontology_file = "kg_demo/data/ontology.json"
        self.ontology.export_ontology(ontology_file)
        print(f"ğŸ“ æœ¬ä½“å·²å¯¼å‡ºåˆ°: {ontology_file}")
        
        print("âœ… ä¸»ä½“å®šä¹‰å®Œæˆ!\n")
        return True
    
    def step2_knowledge_extraction(self):
        """æ­¥éª¤2: çŸ¥è¯†æŠ½å–"""
        print("=" * 60)
        print("ğŸ” æ­¥éª¤2: çŸ¥è¯†æŠ½å– (Knowledge Extraction)")
        print("=" * 60)
        
        # è·å–ç¤ºä¾‹æ–‡æœ¬
        sample_texts = self.sample_data.get_sample_texts()
        print(f"ğŸ“„ å¤„ç† {len(sample_texts)} ä¸ªç¤ºä¾‹æ–‡æœ¬...")
        
        all_extracted_entities = []
        all_extracted_relations = []
        
        for i, text in enumerate(sample_texts):
            print(f"\nğŸ” å¤„ç†æ–‡æœ¬ {i+1}: {text[:50]}...")
            
            # æ–‡æœ¬é¢„å¤„ç†
            processed_text = self.text_extractor.preprocess_text(text)
            keywords = self.text_extractor.extract_keywords(processed_text)
            print(f"   å…³é”®è¯: {keywords[:5]}")
            
            # å®ä½“æŠ½å–
            extracted_entities = self.entity_extractor.extract_entities(processed_text)
            print(f"   æŠ½å–å®ä½“: {len(extracted_entities)} ä¸ª")
            
            # å…³ç³»æŠ½å–
            extracted_relations = self.relation_extractor.extract_relations(
                processed_text, extracted_entities
            )
            print(f"   æŠ½å–å…³ç³»: {len(extracted_relations)} ä¸ª")
            
            all_extracted_entities.extend(extracted_entities)
            all_extracted_relations.extend(extracted_relations)
        
        # æ‰“å°æŠ½å–ç»Ÿè®¡
        print(f"\nğŸ“Š çŸ¥è¯†æŠ½å–ç»Ÿè®¡:")
        print(f"   æ€»å®ä½“æ•°: {len(all_extracted_entities)}")
        print(f"   æ€»å…³ç³»æ•°: {len(all_extracted_relations)}")
        
        # æ˜¾ç¤ºéƒ¨åˆ†æŠ½å–ç»“æœ
        print(f"\nğŸ¯ å®ä½“æŠ½å–ç¤ºä¾‹:")
        for entity in all_extracted_entities[:5]:
            print(f"   - {entity.text} ({entity.type}) - ç½®ä¿¡åº¦: {entity.confidence:.2f}")
        
        print(f"\nğŸ”— å…³ç³»æŠ½å–ç¤ºä¾‹:")
        for relation in all_extracted_relations[:5]:
            print(f"   - {relation.head_entity} -[{relation.relation_type}]-> {relation.tail_entity}")
        
        print("âœ… çŸ¥è¯†æŠ½å–å®Œæˆ!\n")
        return all_extracted_entities, all_extracted_relations
    
    def step3_knowledge_mapping(self, extracted_entities, extracted_relations):
        """æ­¥éª¤3: çŸ¥è¯†æ˜ å°„"""
        print("=" * 60)
        print("ğŸ—ºï¸  æ­¥éª¤3: çŸ¥è¯†æ˜ å°„ (Knowledge Mapping)")
        print("=" * 60)
        
        print("ğŸ”„ è¿›è¡Œå®ä½“æ˜ å°„...")
        
        # æ·»åŠ ä¸€äº›å·²çŸ¥å®ä½“åˆ°æ˜ å°„å™¨
        sample_entities = self.sample_data.get_sample_entities()
        for entity in sample_entities:
            self.entity_mapper.add_known_entity(entity)
        
        # å®ä½“æ˜ å°„
        entity_mappings = self.entity_mapper.batch_map_entities(extracted_entities)
        print(f"   æ˜ å°„ç»“æœ: {len(entity_mappings)} ä¸ªå®ä½“")
        
        # æ‰“å°æ˜ å°„ç»Ÿè®¡
        self.entity_mapper.print_mapping_results(entity_mappings)
        
        print("\nğŸ”„ è¿›è¡Œå…³ç³»æ˜ å°„...")
        
        # æ„å»ºå®ä½“ç±»å‹æ˜ å°„
        entity_type_mapping = {}
        for mapping in entity_mappings:
            if mapping.mapped_entity:
                entity_type_mapping[mapping.extracted_entity.text] = mapping.mapped_entity.type
            else:
                entity_type_mapping[mapping.extracted_entity.text] = mapping.extracted_entity.type
        
        # å…³ç³»æ˜ å°„
        relation_mappings = self.relation_mapper.batch_map_relations(
            extracted_relations, entity_type_mapping
        )
        print(f"   æ˜ å°„ç»“æœ: {len(relation_mappings)} ä¸ªå…³ç³»")
        
        # æ‰“å°å…³ç³»æ˜ å°„ç»Ÿè®¡
        self.relation_mapper.print_mapping_results(relation_mappings)
        
        print("âœ… çŸ¥è¯†æ˜ å°„å®Œæˆ!\n")
        return entity_mappings, relation_mappings
    
    def step4_knowledge_fusion(self, entity_mappings, relation_mappings):
        """æ­¥éª¤4: çŸ¥è¯†èåˆ"""
        print("=" * 60)
        print("ğŸ”„ æ­¥éª¤4: çŸ¥è¯†èåˆ (Knowledge Fusion)")
        print("=" * 60)
        
        print("ğŸ”— å‡†å¤‡èåˆæ•°æ®...")
        
        # å‡†å¤‡å®ä½“æ•°æ®
        entities_to_fuse = []
        for mapping in entity_mappings:
            if mapping.mapped_entity:
                entities_to_fuse.append(mapping.mapped_entity)
            else:
                # åˆ›å»ºæ–°å®ä½“
                new_entity = self.entity_mapper.create_new_entity(
                    mapping.extracted_entity
                )
                entities_to_fuse.append(new_entity)
        
        # å‡†å¤‡å…³ç³»æ•°æ®
        relations_to_fuse = []
        entity_id_map = {entity.name: entity.id for entity in entities_to_fuse}
        
        for mapping in relation_mappings:
            if mapping.mapped_relation_type and mapping.validation_result:
                # è·å–å®ä½“ID
                head_id = entity_id_map.get(mapping.extracted_relation.head_entity)
                tail_id = entity_id_map.get(mapping.extracted_relation.tail_entity)
                
                if head_id and tail_id:
                    relation = Relation(
                        id=f"rel_{len(relations_to_fuse)}",
                        type=mapping.mapped_relation_type,
                        head_entity_id=head_id,
                        tail_entity_id=tail_id,
                        properties={
                            'context': mapping.extracted_relation.context,
                            'source': 'extraction'
                        },
                        confidence=mapping.confidence
                    )
                    relations_to_fuse.append(relation)
        
        print(f"   å‡†å¤‡èåˆ {len(entities_to_fuse)} ä¸ªå®ä½“")
        print(f"   å‡†å¤‡èåˆ {len(relations_to_fuse)} ä¸ªå…³ç³»")
        
        print("\nğŸ”„ è¿›è¡Œå®ä½“èåˆ...")
        entity_fusion_results = self.entity_fusion.batch_fuse_entities(entities_to_fuse)
        self.entity_fusion.print_fusion_results(entity_fusion_results)
        
        print("\nğŸ”„ è¿›è¡Œå…³ç³»èåˆ...")
        relation_fusion_results = self.relation_fusion.batch_fuse_relations(relations_to_fuse)
        self.relation_fusion.print_fusion_results(relation_fusion_results)
        
        print("\nğŸ” æ£€æµ‹å’Œè§£å†³å†²çª...")
        all_entities = [result.fused_entity for result in entity_fusion_results]
        all_relations = [result.fused_relation for result in relation_fusion_results]
        
        entity_conflicts = self.conflict_resolver.detect_entity_conflicts(all_entities)
        relation_conflicts = self.conflict_resolver.detect_relation_conflicts(all_relations)
        
        all_conflicts = entity_conflicts + relation_conflicts
        print(f"   å‘ç° {len(all_conflicts)} ä¸ªå†²çª")
        
        if all_conflicts:
            resolved_conflicts = self.conflict_resolver.batch_resolve_conflicts(all_conflicts)
            self.conflict_resolver.print_conflict_summary(resolved_conflicts)
        
        print("âœ… çŸ¥è¯†èåˆå®Œæˆ!\n")
        return entity_fusion_results, relation_fusion_results
    
    def build_final_knowledge_graph(self, entity_fusion_results, relation_fusion_results):
        """æ„å»ºæœ€ç»ˆçŸ¥è¯†å›¾è°±"""
        print("=" * 60)
        print("ğŸ—ï¸  æ„å»ºæœ€ç»ˆçŸ¥è¯†å›¾è°±")
        print("=" * 60)
        
        print("ğŸ“¦ æ·»åŠ èåˆåçš„å®ä½“å’Œå…³ç³»...")
        
        # æ·»åŠ å®ä½“
        for result in entity_fusion_results:
            self.knowledge_graph.add_entity(result.fused_entity)
        
        # æ·»åŠ å…³ç³»
        successful_relations = 0
        for result in relation_fusion_results:
            try:
                self.knowledge_graph.add_relation(result.fused_relation)
                successful_relations += 1
            except ValueError as e:
                print(f"âš ï¸  è·³è¿‡æ— æ•ˆå…³ç³»: {e}")
                continue
        
        print(f"âœ… æˆåŠŸæ·»åŠ  {len(entity_fusion_results)} ä¸ªå®ä½“")
        print(f"âœ… æˆåŠŸæ·»åŠ  {successful_relations} ä¸ªå…³ç³»")
        
        # éªŒè¯çŸ¥è¯†å›¾è°±
        print(f"\nğŸ” éªŒè¯çŸ¥è¯†å›¾è°±...")
        validation_results = self.knowledge_graph.validate_knowledge_graph()
        
        if validation_results['valid']:
            print("âœ… çŸ¥è¯†å›¾è°±éªŒè¯é€šè¿‡!")
        else:
            print("âš ï¸  çŸ¥è¯†å›¾è°±éªŒè¯å‘ç°é—®é¢˜:")
            for issue in validation_results['issues']:
                print(f"   - {issue}")
        
        # æ‰“å°çŸ¥è¯†å›¾è°±æ‘˜è¦
        print(f"\nğŸ“Š æœ€ç»ˆçŸ¥è¯†å›¾è°±ç»Ÿè®¡:")
        self.knowledge_graph.print_summary()
        
        return self.knowledge_graph
    
    def export_results(self, knowledge_graph):
        """å¯¼å‡ºç»“æœ"""
        print("=" * 60)
        print("ğŸ’¾ å¯¼å‡ºç»“æœ")
        print("=" * 60)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "kg_demo/output"
        os.makedirs(output_dir, exist_ok=True)
        
        # å¯¼å‡ºJSONæ ¼å¼
        json_file = f"{output_dir}/knowledge_graph.json"
        knowledge_graph.export_to_json(json_file)
        print(f"ğŸ“ JSONæ ¼å¼å·²å¯¼å‡ºåˆ°: {json_file}")
        
        # å¯¼å‡ºCSVæ ¼å¼
        entities_csv = f"{output_dir}/entities.csv"
        relations_csv = f"{output_dir}/relations.csv"
        knowledge_graph.export_to_csv(entities_csv, relations_csv)
        print(f"ğŸ“ CSVæ ¼å¼å·²å¯¼å‡ºåˆ°: {entities_csv}, {relations_csv}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        try:
            viz_file = f"{output_dir}/knowledge_graph_visualization.png"
            knowledge_graph.visualize(output_file=viz_file, max_nodes=30)
            print(f"ğŸ“ å¯è§†åŒ–å›¾å·²ä¿å­˜åˆ°: {viz_file}")
        except Exception as e:
            print(f"âš ï¸  å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        
        print("âœ… ç»“æœå¯¼å‡ºå®Œæˆ!\n")
    
    def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸ¯ å¼€å§‹çŸ¥è¯†å›¾è°±æ„å»ºå®Œæ•´æ¼”ç¤º")
        print("=" * 80)
        
        try:
            # æ­¥éª¤1: ä¸»ä½“å®šä¹‰
            self.step1_ontology_definition()
            
            # æ­¥éª¤2: çŸ¥è¯†æŠ½å–
            extracted_entities, extracted_relations = self.step2_knowledge_extraction()
            
            # æ­¥éª¤3: çŸ¥è¯†æ˜ å°„
            entity_mappings, relation_mappings = self.step3_knowledge_mapping(
                extracted_entities, extracted_relations
            )
            
            # æ­¥éª¤4: çŸ¥è¯†èåˆ
            entity_fusion_results, relation_fusion_results = self.step4_knowledge_fusion(
                entity_mappings, relation_mappings
            )
            
            # æ„å»ºæœ€ç»ˆçŸ¥è¯†å›¾è°±
            final_kg = self.build_final_knowledge_graph(
                entity_fusion_results, relation_fusion_results
            )
            
            # å¯¼å‡ºç»“æœ
            self.export_results(final_kg)
            
            print("ğŸ‰ çŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤ºå®Œæˆ!")
            print("=" * 80)
            
            return final_kg
            
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def run_interactive_demo(self):
        """è¿è¡Œäº¤äº’å¼æ¼”ç¤º"""
        print("ğŸ® äº¤äº’å¼çŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤º")
        print("=" * 60)
        
        while True:
            print("\nè¯·é€‰æ‹©è¦æ‰§è¡Œçš„æ­¥éª¤:")
            print("1. ä¸»ä½“å®šä¹‰")
            print("2. çŸ¥è¯†æŠ½å–") 
            print("3. çŸ¥è¯†æ˜ å°„")
            print("4. çŸ¥è¯†èåˆ")
            print("5. å®Œæ•´æ¼”ç¤º")
            print("6. æŸ¥çœ‹å½“å‰å›¾è°±")
            print("0. é€€å‡º")
            
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-6): ").strip()
            
            if choice == '0':
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨çŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤ºç³»ç»Ÿ!")
                break
            elif choice == '1':
                self.step1_ontology_definition()
            elif choice == '2':
                extracted_entities, extracted_relations = self.step2_knowledge_extraction()
                self.extracted_entities = extracted_entities
                self.extracted_relations = extracted_relations
            elif choice == '3':
                if hasattr(self, 'extracted_entities') and hasattr(self, 'extracted_relations'):
                    entity_mappings, relation_mappings = self.step3_knowledge_mapping(
                        self.extracted_entities, self.extracted_relations
                    )
                    self.entity_mappings = entity_mappings
                    self.relation_mappings = relation_mappings
                else:
                    print("âš ï¸  è¯·å…ˆæ‰§è¡ŒçŸ¥è¯†æŠ½å–æ­¥éª¤!")
            elif choice == '4':
                if hasattr(self, 'entity_mappings') and hasattr(self, 'relation_mappings'):
                    entity_fusion_results, relation_fusion_results = self.step4_knowledge_fusion(
                        self.entity_mappings, self.relation_mappings
                    )
                    final_kg = self.build_final_knowledge_graph(
                        entity_fusion_results, relation_fusion_results
                    )
                    self.export_results(final_kg)
                else:
                    print("âš ï¸  è¯·å…ˆæ‰§è¡ŒçŸ¥è¯†æ˜ å°„æ­¥éª¤!")
            elif choice == '5':
                self.run_complete_demo()
            elif choice == '6':
                self.knowledge_graph.print_summary()
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥!")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='çŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤ºç³»ç»Ÿ')
    parser.add_argument('--mode', choices=['complete', 'interactive'], 
                       default='complete', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--step', type=int, choices=[1, 2, 3, 4], 
                       help='åªè¿è¡ŒæŒ‡å®šæ­¥éª¤')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = KnowledgeGraphDemo()
    
    if args.step:
        # è¿è¡ŒæŒ‡å®šæ­¥éª¤
        if args.step == 1:
            demo.step1_ontology_definition()
        elif args.step == 2:
            demo.step2_knowledge_extraction()
        elif args.step == 3:
            print("âš ï¸  å•ç‹¬è¿è¡Œæ­¥éª¤3éœ€è¦å…ˆæ‰§è¡Œæ­¥éª¤2çš„ç»“æœ")
        elif args.step == 4:
            print("âš ï¸  å•ç‹¬è¿è¡Œæ­¥éª¤4éœ€è¦å…ˆæ‰§è¡Œæ­¥éª¤2å’Œ3çš„ç»“æœ")
    elif args.mode == 'interactive':
        demo.run_interactive_demo()
    else:
        demo.run_complete_demo()


if __name__ == "__main__":
    main()